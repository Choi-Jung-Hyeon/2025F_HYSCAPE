#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""í•œêµ­ìˆ˜ì†Œì—°í•©(H2HUB) ë¸Œë¦¬í•‘ ìë™í™” ì‹œìŠ¤í…œ - ë©”ì¸"""

import logging
import sys
import argparse
import re
from pathlib import Path

from article_collector import H2HUBBriefingCollector
from article_analyzer import BriefingAnalyzer
from notion_uploader import NotionUploader
import config

logging.basicConfig(
    level=getattr(logging, config.LOG_LEVEL),
    format=config.LOG_FORMAT
)
logger = logging.getLogger(__name__)


class H2HubAutomation:
    """H2HUB ë¸Œë¦¬í•‘ ìë™í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.collector = H2HUBBriefingCollector()
        self.analyzer = BriefingAnalyzer()
        self.uploader = NotionUploader()
        logger.info("âœ… ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def run_full_workflow(self, num_pages: int = 1, upload_to_notion: bool = True):
        """ì „ì²´ ì›Œí¬í”Œë¡œìš° (ìˆ˜ì§‘ â†’ ë¶„ì„ â†’ ì—…ë¡œë“œ)"""
        logger.info("\n" + "="*70)
        logger.info("STEP 1: ë¸Œë¦¬í•‘ PDF ìˆ˜ì§‘")
        logger.info("="*70)
        
        # ìˆ˜ì§‘
        briefings = self.collector.collect_briefings(max_pages=num_pages)
        
        if not briefings:
            logger.warning("âš ï¸ ìˆ˜ì§‘ëœ ë¸Œë¦¬í•‘ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        logger.info(f"\nâœ… {len(briefings)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
        
        # ë¶„ì„ ë° ì—…ë¡œë“œ
        logger.info("\n" + "="*70)
        logger.info("STEP 2: ë¶„ì„ ë° ì—…ë¡œë“œ")
        logger.info("="*70)
        
        success, fail = 0, 0
        
        for i, briefing in enumerate(briefings, 1):
            logger.info(f"\n[{i}/{len(briefings)}] {briefing['title']}")
            
            try:
                analysis = self.analyzer.analyze_briefing(briefing['pdf_path'])
                
                if not analysis:
                    logger.warning("  âš ï¸ ë¶„ì„ ì‹¤íŒ¨")
                    fail += 1
                    continue
                
                if upload_to_notion:
                    briefing_data = {**briefing, **analysis}
                    if self.uploader.upload_briefing(briefing_data):
                        success += 1
                    else:
                        fail += 1
                else:
                    self._print_analysis(analysis)
                    success += 1
            except Exception as e:
                logger.error(f"  âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                fail += 1
        
        self._print_summary(success, fail)
    
    def run_with_existing_pdfs(self, pdf_dir: Path, upload_to_notion: bool = True):
        """ê¸°ì¡´ PDF íŒŒì¼ ë¶„ì„"""
        logger.info("\n" + "="*70)
        logger.info("ê¸°ì¡´ PDF íŒŒì¼ ë¶„ì„ ëª¨ë“œ")
        logger.info("="*70)
        logger.info(f"ë””ë ‰í† ë¦¬: {pdf_dir}")
        
        pdf_files = sorted(pdf_dir.glob("*.pdf"))
        
        if not pdf_files:
            logger.warning(f"âš ï¸ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pdf_dir}")
            return
        
        logger.info(f"\nâœ… {len(pdf_files)}ê°œ PDF íŒŒì¼ ë°œê²¬")
        
        success, fail = 0, 0
        
        for i, pdf_file in enumerate(pdf_files, 1):
            logger.info(f"\n[{i}/{len(pdf_files)}] {pdf_file.name}")
            
            try:
                analysis = self.analyzer.analyze_briefing(str(pdf_file))
                
                if not analysis:
                    logger.warning("  âš ï¸ ë¶„ì„ ì‹¤íŒ¨")
                    fail += 1
                    continue
                
                briefing_data = {
                    'title': pdf_file.stem,
                    'date': self._extract_date(pdf_file.name),
                    'url': f'file://{pdf_file.absolute()}',
                    'pdf_path': str(pdf_file),
                    **analysis
                }
                
                if upload_to_notion:
                    if self.uploader.upload_briefing(briefing_data):
                        success += 1
                    else:
                        fail += 1
                else:
                    self._print_analysis(analysis)
                    success += 1
            except Exception as e:
                logger.error(f"  âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                fail += 1
        
        self._print_summary(success, fail)
    
    def _extract_date(self, filename: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ (YYMMDD â†’ YYYY-MM-DD)"""
        match = re.search(r'(\d{2})(\d{2})(\d{2})', filename)
        if match:
            yy, mm, dd = match.groups()
            return f"20{yy}-{mm}-{dd}"
        return ""
    
    def _print_analysis(self, analysis: dict):
        """ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        print(f"\n    ê°ì„±: {analysis['sentiment']}")
        print(f"    ì¹´í…Œê³ ë¦¬: {analysis.get('category', 'N/A')}")
        print(f"    í‚¤ì›Œë“œ: {', '.join(analysis.get('keywords', []))}")
        print(f"    ìš”ì•½: {analysis['summary'][:100]}...")
    
    def _print_summary(self, success: int, fail: int):
        """ìµœì¢… ê²°ê³¼ ì¶œë ¥"""
        logger.info("\n" + "="*70)
        logger.info("ì‘ì—… ì™„ë£Œ")
        logger.info("="*70)
        logger.info(f"âœ… ì„±ê³µ: {success}ê°œ")
        logger.info(f"âŒ ì‹¤íŒ¨: {fail}ê°œ")
        logger.info(f"ğŸ“Š ì´ ì²˜ë¦¬: {success + fail}ê°œ")
        logger.info("="*70 + "\n")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="í•œêµ­ìˆ˜ì†Œì—°í•© ë¸Œë¦¬í•‘ ìë™í™” ì‹œìŠ¤í…œ"
    )
    
    parser.add_argument(
        '--pages',
        type=int,
        default=0,
        help='ì›¹ì—ì„œ ìˆ˜ì§‘í•  í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸: 0)'
    )
    
    parser.add_argument(
        '--existing-pdfs',
        type=str,
        help='ê¸°ì¡´ PDF ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì˜ˆ: /mnt/project)'
    )
    
    parser.add_argument(
        '--no-upload',
        action='store_true',
        help='Notion ì—…ë¡œë“œ ê±´ë„ˆë›°ê¸° (ë¶„ì„ë§Œ)'
    )
    
    parser.add_argument(
        '--test-notion',
        action='store_true',
        help='Notion ì—°ê²° í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰'
    )
    
    args = parser.parse_args()
    
    # Notion ì—°ê²° í…ŒìŠ¤íŠ¸
    if args.test_notion:
        print("\n" + "="*70)
        print("Notion ì—°ê²° í…ŒìŠ¤íŠ¸")
        print("="*70)
        uploader = NotionUploader()
        uploader.test_connection()
        return
    
    # ì‹œìŠ¤í…œ ì‹œì‘
    logger.info("\n" + "="*70)
    logger.info("í•œêµ­ìˆ˜ì†Œì—°í•© ë¸Œë¦¬í•‘ ìë™í™” ì‹œìŠ¤í…œ ì‹œì‘")
    logger.info("="*70)
    
    automation = H2HubAutomation()
    upload_to_notion = not args.no_upload
    
    # ê¸°ì¡´ PDF ëª¨ë“œ
    if args.existing_pdfs:
        pdf_dir = Path(args.existing_pdfs)
        if not pdf_dir.exists():
            logger.error(f"âŒ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_dir}")
            sys.exit(1)
        automation.run_with_existing_pdfs(pdf_dir, upload_to_notion)
    
    # ì›¹ ìˆ˜ì§‘ ëª¨ë“œ
    elif args.pages > 0:
        automation.run_full_workflow(args.pages, upload_to_notion)
    
    else:
        parser.print_help()
        print("\nâŒ --pages ë˜ëŠ” --existing-pdfs ì˜µì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        sys.exit(1)


if __name__ == "__main__":
    main()