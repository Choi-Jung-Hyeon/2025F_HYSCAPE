#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""PDF ë¸Œë¦¬í•‘ ë¶„ì„ ëª¨ë“ˆ"""

import logging
import json
import re
from pathlib import Path
from typing import Dict, Optional

import pdfplumber
import google.generativeai as genai

import config

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class BriefingAnalyzer:
    """PDF ë¸Œë¦¬í•‘ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        genai.configure(api_key=config.GOOGLE_API_KEY)
        self.model = genai.GenerativeModel(config.GEMINI_MODEL)
        logger.info(f"BriefingAnalyzer ì´ˆê¸°í™” (ëª¨ë¸: {config.GEMINI_MODEL})")
    
    def analyze_briefing(self, pdf_path: str) -> Optional[Dict]:
        """PDF ë¸Œë¦¬í•‘ íŒŒì¼ ë¶„ì„"""
        logger.info(f"\nğŸ“Š ë¶„ì„ ì‹œì‘: {Path(pdf_path).name}")
        
        text = self._extract_text_from_pdf(pdf_path)
        
        if not text or len(text.strip()) < 100:
            logger.warning(f"  âš ï¸ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ ({len(text)} ì)")
            return None
        
        logger.info(f"  âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ ({len(text)} ì)")
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¼ ì „ëµ ì„ íƒ
        analysis = self._analyze_with_gemini(text[:10000])
        
        if not analysis:
            # ì¬ì‹œë„: ë” ì§§ì€ í…ìŠ¤íŠ¸
            logger.info("  ğŸ”„ ì§§ì€ í…ìŠ¤íŠ¸ë¡œ ì¬ì‹œë„...")
            analysis = self._analyze_with_gemini(text[:5000])
        
        if analysis:
            logger.info(f"  âœ… ë¶„ì„ ì™„ë£Œ")
            logger.info(f"     ê°ì„±: {analysis['sentiment']}")
            logger.info(f"     ì¹´í…Œê³ ë¦¬: {analysis.get('category', 'N/A')}")
            logger.info(f"     í‚¤ì›Œë“œ: {', '.join(analysis.get('keywords', []))}")
        
        return analysis
    
    def _extract_text_from_pdf(self, pdf_path: str) -> str:
        """PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            text_parts = []
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text_parts.append(page_text)
            
            full_text = "\n\n".join(text_parts)
            full_text = re.sub(r'\n{3,}', '\n\n', full_text)
            full_text = re.sub(r' {2,}', ' ', full_text)
            
            return full_text.strip()
        except Exception as e:
            logger.error(f"  âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def _analyze_with_gemini(self, text: str) -> Optional[Dict]:
        """Gemini APIë¡œ í…ìŠ¤íŠ¸ ë¶„ì„"""
        try:
            prompt = config.ANALYSIS_PROMPT.format(content=text)
            
            safety_settings = {
                genai.types.HarmCategory.HARM_CATEGORY_HATE_SPEECH: genai.types.HarmBlockThreshold.BLOCK_NONE,
                genai.types.HarmCategory.HARM_CATEGORY_HARASSMENT: genai.types.HarmBlockThreshold.BLOCK_NONE,
                genai.types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: genai.types.HarmBlockThreshold.BLOCK_NONE,
                genai.types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: genai.types.HarmBlockThreshold.BLOCK_NONE,
            }
            
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.3,
                    max_output_tokens=800
                ),
                safety_settings=safety_settings
            )
            
            if not response.candidates or response.candidates[0].finish_reason != 1:
                return None
            
            # JSON íŒŒì‹±
            result_text = response.text.strip()
            json_text = self._extract_json(result_text)
            analysis = json.loads(json_text)
            
            if self._validate_analysis(analysis):
                return analysis
            
            return None
        except Exception as e:
            logger.warning(f"  âš ï¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None
    
    def _extract_json(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ JSON ì¶”ì¶œ"""
        text = re.sub(r'```json\s*', '', text, flags=re.IGNORECASE)
        text = re.sub(r'```\s*', '', text)
        
        start = text.find('{')
        if start == -1:
            return text.strip()
        
        count = 0
        end = start
        for i in range(start, len(text)):
            if text[i] == '{':
                count += 1
            elif text[i] == '}':
                count -= 1
                if count == 0:
                    end = i + 1
                    break
        
        return text[start:end].strip() if end > start else text.strip()
    
    def _validate_analysis(self, analysis: Dict) -> bool:
        """ë¶„ì„ ê²°ê³¼ ê²€ì¦ ë° ìë™ ë³´ì •"""
        required_keys = ['summary', 'sentiment', 'category', 'keywords']
        
        for key in required_keys:
            if key not in analysis:
                logger.warning(f"  í•„ìˆ˜ í‚¤ ëˆ„ë½: {key}")
                return False
        
        # summary ê²€ì¦
        if not isinstance(analysis['summary'], str) or len(analysis['summary']) < 10:
            return False
        
        # sentiment ìë™ ë³´ì •
        valid_sentiments = ['Positive', 'Negative', 'Neutral']
        if analysis['sentiment'] not in valid_sentiments:
            sentiment_lower = str(analysis['sentiment']).lower()
            if 'positive' in sentiment_lower or 'ê¸ì •' in sentiment_lower:
                analysis['sentiment'] = 'Positive'
            elif 'negative' in sentiment_lower or 'ë¶€ì •' in sentiment_lower:
                analysis['sentiment'] = 'Negative'
            else:
                analysis['sentiment'] = 'Neutral'
        
        # category ìë™ ë³´ì •
        valid_categories = ['ê¸°ê´€', 'ì •ì±…', 'ì§€ìì²´', 'ì‚°ì—…ê³„', 'ì—°êµ¬ê³„', 'í•´ì™¸']
        if analysis['category'] not in valid_categories:
            analysis['category'] = 'ê¸°ê´€'
        
        # keywords ìë™ ë³´ì •
        if not isinstance(analysis['keywords'], list):
            if isinstance(analysis['keywords'], str):
                analysis['keywords'] = [kw.strip() for kw in analysis['keywords'].split(',')]
            else:
                analysis['keywords'] = []
        
        # ìµœëŒ€ 5ê°œë¡œ ì œí•œ
        analysis['keywords'] = [kw for kw in analysis['keywords'] if kw.strip()][:5]
        
        return True


def main():
    """í…ŒìŠ¤íŠ¸ìš©"""
    sample_pdf = Path("/mnt/project/250925_ì¼ê°„_ìˆ˜ì†Œ_ì´ìŠˆ_ë¸Œë¦¬í•‘.pdf")
    
    if not sample_pdf.exists():
        print(f"âŒ íŒŒì¼ ì—†ìŒ: {sample_pdf}")
        return
    
    analyzer = BriefingAnalyzer()
    result = analyzer.analyze_briefing(str(sample_pdf))
    
    if result:
        print("\në¶„ì„ ê²°ê³¼:")
        print(f"ê°ì„±: {result['sentiment']}")
        print(f"ì¹´í…Œê³ ë¦¬: {result['category']}")
        print(f"í‚¤ì›Œë“œ: {', '.join(result['keywords'])}")
        print(f"\nìš”ì•½:\n{result['summary']}")
    else:
        print("\nâŒ ë¶„ì„ ì‹¤íŒ¨")


if __name__ == "__main__":
    main()